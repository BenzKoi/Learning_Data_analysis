{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model comparison (Iris dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pandas  version = {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('https://github.com/prasertcbs/basic-dataset/raw/master/iris.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']], \n",
    "    df.species, \n",
    "    test_size=test_size, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier() # step 1: choose model/estimator\n",
    "# model=LogisticRegression()\n",
    "model.fit(X_train, y_train) # step 2: fit\n",
    "y_pred=model.predict(X_test) # step 3: predict\n",
    "model.score(X_test, y_test) # step 4: score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsClassifier() # step 1: choose model/estimator\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train, y_train) # step 2: fit\n",
    "y_pred=model.predict(X_test) # step 3: predict\n",
    "model.score(X_test, y_test) # step 4: score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsClassifier() # step 1: choose model/estimator\n",
    "model=GaussianNB()\n",
    "model.fit(X_train, y_train) # step 2: fit\n",
    "y_pred=model.predict(X_test) # step 3: predict\n",
    "model.score(X_test, y_test) # step 4: score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = [\n",
    "    [KNeighborsClassifier(n_neighbors=10), 'KNeighborsClassifier'],\n",
    "    [LogisticRegression(solver='lbfgs'), 'LogisticRegression'],\n",
    "    [GaussianNB(), 'GaussianNB'],\n",
    "    [GradientBoostingClassifier(), 'GradientBoostingClassifier'],\n",
    "    [RandomForestClassifier(), 'RandomForestClassifier'],\n",
    "    [AdaBoostClassifier(), 'AdaBoostClassifier']\n",
    "]\n",
    "model_score=[]\n",
    "for a in algo:\n",
    "    model=a[0]\n",
    "    model.fit(X_train, y_train) # step 2: fit\n",
    "    y_pred=model.predict(X_test) # step 3: predict\n",
    "    score=model.score(X_test, y_test)\n",
    "    model_score.append([score, a[1]])\n",
    "    print(f'{a[1]} score = {score}') # step 4: score\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print('-' * 100)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscore=pd.DataFrame(model_score, columns=['score', 'classifier'])\n",
    "dscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscore.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
